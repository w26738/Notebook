{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络 - MNIST数据集分类 ##\n",
    "参考:\n",
    "1. Giancarlo Zaccone, Getting Started with TensorFlow, 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备数据和定义模型变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting D:\\Code\\GitHub\\notebook\\datasets\\mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting D:\\Code\\GitHub\\notebook\\datasets\\mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting D:\\Code\\GitHub\\notebook\\datasets\\mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting D:\\Code\\GitHub\\notebook\\datasets\\mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "one_hot：一个长度为n的数组，只有一个元素是1，其他元素是0。\n",
    "比如为了表示0..9个数字，数字1的one hot编码为[0 1 0 0 0 0 0 0 0 0]\n",
    "数字9的one hot编码为[0 0 0 0 0 0 0 0 1 0]\n",
    "'''\n",
    "mnist = input_data.read_data_sets(r'D:\\Code\\GitHub\\notebook\\datasets\\mnist', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 了解MNIST数据集 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784) (55000, 10)\n",
      "(10000, 784) (10000, 10)\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "img_data shape = (784,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0ERfiAowg8ERfiBoAg/ENQ/AfOxgWMCOc1JAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd6cff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(mnist.train.images.shape, mnist.train.labels.shape)\n",
    "print(mnist.test.images.shape, mnist.test.labels.shape)\n",
    "img1 = mnist.train.images[1]\n",
    "label1 = mnist.train.labels[1]\n",
    "print(label1)\n",
    "print('img_data shape =', img1.shape)\n",
    "img1 = img1.reshape(28, 28)\n",
    "plt.imshow(img1, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 学习率\n",
    "learning_rate = 0.001 \n",
    "# 训练迭代次数\n",
    "training_iters = 38400\n",
    "# 一个训练批次中训练数据的个数。数字越小表示训练过程越接近\n",
    "batch_size = 128\n",
    "# 控制输出打印频率\n",
    "display_step = 10\n",
    "# 输入层节点数，这里指每个数字的像素个数28*28\n",
    "n_input = 784\n",
    "# 输出节点数，这里指MNIST标签个数0..9\n",
    "n_classes = 10\n",
    "# dropout是指在深度学习网络的训练过程中，为了避免过拟合，按照一定的概率将一部分神经网络单元从网络中丢弃\n",
    "dropout = 0.75\n",
    "\n",
    "# 定义输入图的占位符，并转换为4维张量\n",
    "x = tf.placeholder(tf.float32, [None,n_input])\n",
    "# x变成一个4d向量，其第2、第3维对应图片的宽、高，最后一维代表图片的颜色通道数(因为是灰度图所以这里的通道数为1，如果是rgb彩色图，则为3)\n",
    "_X = tf.reshape(x, shape=[-1,28,28,1])\n",
    "# 定义输出图的占位符\n",
    "y_ = tf.placeholder(tf.float32, [None,n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一卷积层 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把_X和权值向量进行卷积，加上偏置项，然后应用ReLU激活函数，最后进行max pooling（池化），用下面两个函数完成\n",
    "# 这里卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。\n",
    "def conv2d(img, w, b):\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(img, w , strides=[1,1,1,1], padding='SAME'), b))\n",
    "\n",
    "def max_pool(img, k):\n",
    "    return tf.nn.max_pool(img, ksize=[1,k,k,1], strides=[1,k,k,1], padding='SAME')\n",
    "\n",
    "# 为了识别每个图形，需要进行特征映射，这里假设有32个特征。\n",
    "# 卷积的权重张量形状是[5, 5, 1, 32]，前两个维度是patch的大小，接着是输入的通道数目，最后是输出的通道数目，而对于每一个输出通道都有一个对应的偏置量。\n",
    "wc1 = tf.Variable(tf.truncated_normal([5,5,1,32], stddev=0.1))\n",
    "bc1 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "# 把_X和权值向量进行卷积，加上偏置项，应用ReLU激活函数，并进行max pooling（池化），经过第一卷积层，图形shape从28*28缩减为14*14\n",
    "conv1 = conv2d(_X, wc1, bc1)\n",
    "conv1 = max_pool(conv1, k=2)\n",
    "# 使用dropout丢弃一定数量的神经元\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "conv1 = tf.nn.dropout(conv1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二卷积层 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 对于第二卷积层，假设有64个特征映射\n",
    "wc2 = tf.Variable(tf.truncated_normal([5,5,32,64], stddev=0.1))\n",
    "bc2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "# 同第一卷积层进行卷积、池化和dropout操作，经过第二卷积层，图形shape从14*14缩减为7*7\n",
    "conv2 = conv2d(conv1, wc2, bc2)\n",
    "conv2 = max_pool(conv2, k=2)\n",
    "conv2 = tf.nn.dropout(conv2, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 这里加入一个神经元数目为1024的全连接层来处理所有图像。将最后的\n",
    "wd1 = tf.Variable(tf.truncated_normal([7*7*64, 1024], stddev=0.1))\n",
    "bd1 = tf.Variable(tf.truncated_normal([1024], stddev=0.1))\n",
    "# 池化层的输出reshape为一个一维向量，与权值相乘，加上偏置通过一个ReLu函数\n",
    "dense1 = tf.reshape(conv2, [-1,wd1.get_shape().as_list()[0]])\n",
    "dense1 = tf.nn.relu(tf.add(tf.matmul(dense1, wd1), bd1))\n",
    "dense1 = tf.nn.dropout(dense1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wout = tf.Variable(tf.truncated_normal([1024, n_classes], stddev=0.1))\n",
    "bout = tf.Variable(tf.truncated_normal([n_classes], stddev=0.1))\n",
    "y = tf.add(tf.matmul(dense1,wout), bout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练和模型评估 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter1280, Minibatch Loss= 1.885419, Traning Accuracy= 0.42188\n",
      "Iter2560, Minibatch Loss= 2.035804, Traning Accuracy= 0.46875\n",
      "Iter3840, Minibatch Loss= 1.377633, Traning Accuracy= 0.70312\n",
      "Iter5120, Minibatch Loss= 0.722307, Traning Accuracy= 0.80469\n",
      "Iter6400, Minibatch Loss= 0.569240, Traning Accuracy= 0.85938\n",
      "Iter7680, Minibatch Loss= 0.472883, Traning Accuracy= 0.88281\n",
      "Iter8960, Minibatch Loss= 0.338574, Traning Accuracy= 0.90625\n",
      "Iter10240, Minibatch Loss= 0.412773, Traning Accuracy= 0.88281\n",
      "Iter11520, Minibatch Loss= 0.357687, Traning Accuracy= 0.91406\n",
      "Iter12800, Minibatch Loss= 0.151524, Traning Accuracy= 0.96094\n",
      "Iter14080, Minibatch Loss= 0.183404, Traning Accuracy= 0.96094\n",
      "Iter15360, Minibatch Loss= 0.254209, Traning Accuracy= 0.92969\n",
      "Iter16640, Minibatch Loss= 0.131617, Traning Accuracy= 0.95312\n",
      "Iter17920, Minibatch Loss= 0.248641, Traning Accuracy= 0.92969\n",
      "Iter19200, Minibatch Loss= 0.094253, Traning Accuracy= 0.98438\n",
      "Iter20480, Minibatch Loss= 0.160645, Traning Accuracy= 0.95312\n",
      "Iter21760, Minibatch Loss= 0.111763, Traning Accuracy= 0.96875\n",
      "Iter23040, Minibatch Loss= 0.215864, Traning Accuracy= 0.93750\n",
      "Iter24320, Minibatch Loss= 0.166508, Traning Accuracy= 0.94531\n",
      "Iter25600, Minibatch Loss= 0.069776, Traning Accuracy= 0.98438\n",
      "Iter26880, Minibatch Loss= 0.095152, Traning Accuracy= 0.97656\n",
      "Iter28160, Minibatch Loss= 0.122215, Traning Accuracy= 0.96875\n",
      "Iter29440, Minibatch Loss= 0.091367, Traning Accuracy= 0.96875\n",
      "Iter30720, Minibatch Loss= 0.116291, Traning Accuracy= 0.96875\n",
      "Iter32000, Minibatch Loss= 0.139834, Traning Accuracy= 0.94531\n",
      "Iter33280, Minibatch Loss= 0.045956, Traning Accuracy= 1.00000\n",
      "Iter34560, Minibatch Loss= 0.084068, Traning Accuracy= 0.97656\n",
      "Iter35840, Minibatch Loss= 0.103699, Traning Accuracy= 0.97656\n",
      "Iter37120, Minibatch Loss= 0.088785, Traning Accuracy= 0.97656\n",
      "Optimization Finished\n",
      "Testing Accuracy: 0.984375\n"
     ]
    }
   ],
   "source": [
    "# 成本函数\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "# 优化模型\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# 测试评估模型\n",
    "# argmax给出给定张量中在指定轴axis上的最大值的位置（索引）\n",
    "correct_pred = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "# 计算准确度accuracy，cast函数是类型转换函数，将索引值转换为浮点数\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# 运行图\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    while step*batch_size < training_iters:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optimizer, feed_dict={x:batch_xs, y_:batch_ys, keep_prob:dropout})\n",
    "        if step%display_step == 0:\n",
    "            acc = sess.run(accuracy, feed_dict={x:batch_xs, y_:batch_ys, keep_prob:1.0})\n",
    "            loss = sess.run(cost, feed_dict={x:batch_xs, y_:batch_ys, keep_prob:1.0})\n",
    "            print('Iter'+str(step*batch_size)+', Minibatch Loss= '+'{:.6f}'.format(loss)+', Traning Accuracy= '+'{:.5f}'.format(acc))\n",
    "        step += 1\n",
    "    print('Optimization Finished')\n",
    "    print('Testing Accuracy:', sess.run(accuracy, feed_dict={x: mnist.test.images[:256], y_: mnist.test.labels[:256], keep_prob:1.0}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
