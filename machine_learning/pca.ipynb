{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** <font size=4>主成分分析PCA</font>  ** \n",
    "\n",
    "Ref: Gavin Hackeling, Mastering Machine Learning with scikit-learn, 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "降维致力于解决三类问题：\n",
    "1. 降维可以缓解维度灾难问题。\n",
    "2. 降维可以在压缩数据的同时让信息损失最小化。\n",
    "3. 理解几百个维度的数据结构很困难，两三个维度的数据通过可视化更容易理解。\n",
    "\n",
    "PCA将数据投射到一个低维子空间实现降维。\n",
    "主成分可以通过两种方法计算：\n",
    "1. 计算数据协方差矩阵。协方差矩阵是方阵，所有我们可以用前面的方法计算特征值和特征向量。 (http://blog.csdn.net/ybdesire/article/details/6270328/)\n",
    "2. 用数据矩阵的奇异值分解（SVD）来找协方差矩阵的特征向量和特征值的平方根。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THe original dimensions of the training data were: (300, 10304)\n",
      "THe reduced dimensions of the training data were: (300, 150)\n",
      "Cross validation accuracy: 0.870778410104 [ 0.85714286  0.87878788  0.87640449]\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      " d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s1       1.00      0.33      0.50         3\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s10       1.00      1.00      1.00         2\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s11       1.00      1.00      1.00         1\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s12       1.00      1.00      1.00         5\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s13       0.33      1.00      0.50         1\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s14       1.00      1.00      1.00         1\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s15       0.50      1.00      0.67         1\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s16       1.00      0.80      0.89         5\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s17       1.00      1.00      1.00         4\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s18       1.00      1.00      1.00         3\n",
      " d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s2       1.00      1.00      1.00         3\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s20       1.00      1.00      1.00         1\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s21       1.00      1.00      1.00         1\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s22       0.67      0.67      0.67         3\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s23       1.00      1.00      1.00         2\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s24       1.00      1.00      1.00         1\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s25       1.00      1.00      1.00         1\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s26       1.00      1.00      1.00         1\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s27       1.00      1.00      1.00         3\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s28       1.00      0.33      0.50         3\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s29       1.00      1.00      1.00         3\n",
      " d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s3       1.00      1.00      1.00         3\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s30       1.00      0.80      0.89         5\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s31       0.75      1.00      0.86         3\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s32       1.00      1.00      1.00         1\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s33       0.67      1.00      0.80         2\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s34       1.00      1.00      1.00         4\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s35       0.67      1.00      0.80         2\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s36       1.00      0.80      0.89         5\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s37       0.75      1.00      0.86         3\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s38       1.00      1.00      1.00         4\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s39       1.00      0.83      0.91         6\n",
      " d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s4       1.00      1.00      1.00         1\n",
      "d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s40       0.67      0.50      0.57         4\n",
      " d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s5       0.33      0.50      0.40         2\n",
      " d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s6       1.00      1.00      1.00         4\n",
      " d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s7       0.00      0.00      0.00         0\n",
      " d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s8       1.00      1.00      1.00         2\n",
      " d:\\Code\\GitHub\\notebook\\datasets\\att_faces\\s9       1.00      1.00      1.00         1\n",
      "\n",
      "                                   avg / total       0.92      0.88      0.88       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 例子：P解决一个脸部识别问题，脸部识别是一个监督分类任务，用于从照片中认出某个人。\n",
    "from os import walk, path\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "FILE_PATH = r'd:\\Code\\GitHub\\notebook\\datasets\\att_faces'\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for dir_path, dir_names, file_name in walk(FILE_PATH):\n",
    "    for fn in file_name:\n",
    "        if fn[-3:] == 'pgm':\n",
    "            image_filename = path.join(dir_path, fn)\n",
    "            # 使用sklearn.preprocessing.scale()函数，对数据中的特征进行归一化（normalize），让其具有零平均值（zero-mean）和单位方差（unit variance）\n",
    "            X.append(scale(mh.imread(image_filename, as_grey=True).reshape(10304).astype('float32')))\n",
    "            y.append(dir_path)\n",
    "\n",
    "X = np.array(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "pca = PCA(n_components = 150)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "print('The original dimensions of the training data were:', X_train.shape)\n",
    "print('The reduced dimensions of the training data were:', X_train_reduced.shape)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "accuracy = cross_val_score(classifier, X_train_reduced, y_train)\n",
    "\n",
    "print('Cross validation accuracy:', np.mean(accuracy), accuracy)\n",
    "classifier.fit(X_train_reduced, y_train)\n",
    "prediction = classifier.predict(X_test_reduced)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
